---
layout: page
title: About me
subtitle: Welcome to my Personal Website.
---

<div style="text-align : center;">
     <img src="/assets/img/aboutme2.jpg" width="270" height="270" style="border-radius: 10px;">
</div>

<h3 style="text-align: center;"><strong>Wonjeong Choi</strong></h3>

---

<p>Ph.D. @ KAIST EE<br>
<strong>Research Interest:</strong> Multi-modal Foundation Models, Post-Training Strategies, ML Robustness<br>
<strong>E-mail:</strong> dnjswjd5457 (at) kaist.ac.kr</p>

---

<!--
I am a Ph.D. student in [School of Electrical Engineering (EE), KAIST](https://ee.kaist.ac.kr/en/), under the supervision of Prof. Jaekyun Moon (in [MoonLab](http://moonlab.kaist.ac.kr)\). Our laboratory has been studying in a wide range of research topics on hardware-friendly and robust machine learning algorithms. My own research emphasizes on developing **trustworthy AI systems** for safety-critical applications such as automotive, medical diagnosis, and manufactorying systems. In particular, I have explored the following areas:

1) **Post-Training for Large Models**: Test-Time Adaptation, Mask Tuning, Few-Shot Tuning, Transfer Learning<br> 
2) **Out-of-Domain (OOD) Robustness**: Domain Adaptation/Generalization<br>
3) **Trustworthy AI**: LLM Safety, Model Calibration, Adversarial Attack<br>
-->

I received my Ph.D. degree from [School of Electrical Engineering (EE), KAIST](https://ee.kaist.ac.kr/en/), under the supervision of Prof. Jaekyun Moon (in [MoonLab](http://moonlab.kaist.ac.kr)\). I have been working on **hardware-friendly and robust ML algorithms** for developing trustworthy AI systems in safety-critical applications (e.g., automotive/medical/manufactorying systems). In particular, I have explored the following areas:

1) **Multi-modal Foundation Models**: Vision-Language (VLM), Vision-Language-Action (VaLA), Vision-Language-Navigation (VLN)<br>
2) **Post-Training Strategies**: Transfer Learning, Few-Shot Learning, Test-Time Adaptation, Mask Tuning<br>
3) **ML Robustness**: Domain Adaptation/Generalization, Model Calibration, Adversarial Attack<br>

Iâ€™m open to any talks/discussions/suggestions you might have :)



